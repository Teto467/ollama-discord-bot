# --- START OF FILE bot.py ---

import asyncio
import sys
import os
import json
import logging
import datetime
import time
from collections import defaultdict, deque
import math # NaNãƒã‚§ãƒƒã‚¯ç”¨ã«è¿½åŠ 
import functools # run_in_executorç”¨ã«è¿½åŠ 

import discord
from discord import app_commands, Embed
from discord.ext import commands, tasks # tasksã‚’è¿½åŠ 
from dotenv import load_dotenv
import aiohttp
try:
    import aiofiles # éåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«I/Oç”¨
except ImportError:
    aiofiles = None # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¤±æ•—æ™‚ã®ãƒ•ãƒ©ã‚°

# --- Windowsç”¨ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãƒãƒªã‚·ãƒ¼ã®è¨­å®š ---
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
        # logging.FileHandler("bot.log", encoding="utf-8")
    ]
)
logger = logging.getLogger('ollama_bot')

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
TOKEN = os.getenv('DISCORD_TOKEN')
OLLAMA_API_URL = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
DEFAULT_MODEL = os.getenv('DEFAULT_MODEL')
try:
    CHAT_CHANNEL_ID = int(os.getenv('CHAT_CHANNEL_ID'))
except (TypeError, ValueError):
    logger.error("ç’°å¢ƒå¤‰æ•° 'CHAT_CHANNEL_ID' ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€æ•´æ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚BOTã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    sys.exit(1)
try:
    HISTORY_LIMIT = int(os.getenv('HISTORY_LIMIT', '50'))
except ValueError:
    logger.warning("ç’°å¢ƒå¤‰æ•° 'HISTORY_LIMIT' ã®å€¤ãŒä¸æ­£ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®50ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    HISTORY_LIMIT = 50
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ­ãƒ¼ãƒ‰é–“éš”ï¼ˆåˆ†ï¼‰
try:
    PROMPT_RELOAD_INTERVAL_MINUTES = float(os.getenv('PROMPT_RELOAD_INTERVAL', '5.0'))
except ValueError:
    logger.warning("ç’°å¢ƒå¤‰æ•° 'PROMPT_RELOAD_INTERVAL' ã®å€¤ãŒä¸æ­£ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®5.0åˆ†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    PROMPT_RELOAD_INTERVAL_MINUTES = 5.0
# ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°é–“éš”ï¼ˆåˆ†ï¼‰ - ã‚ªãƒ¼ãƒˆã‚³ãƒ³ãƒ—ãƒªãƒ¼ãƒˆç”¨
try:
    MODEL_UPDATE_INTERVAL_MINUTES = float(os.getenv('MODEL_UPDATE_INTERVAL', '15.0'))
except ValueError:
    logger.warning("ç’°å¢ƒå¤‰æ•° 'MODEL_UPDATE_INTERVAL' ã®å€¤ãŒä¸æ­£ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®15.0åˆ†ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    MODEL_UPDATE_INTERVAL_MINUTES = 15.0


# --- BOTè¨­å®š ---
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° & å®šæ•° ---
active_model = DEFAULT_MODEL
# å„ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿æŒ (None ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨)
system_prompts: dict[str, str | None] = defaultdict(lambda: None)

PROMPT_DIR_NAME = "prompts"
available_prompts: dict[str, str] = {} # prompts ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

available_ollama_models: list[str] = [] # ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨

PROMPT_NAME_DEFAULT = "[ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ]"

channel_data = defaultdict(lambda: {
    "history": deque(maxlen=HISTORY_LIMIT),
    "params": {"temperature": 0.7},
    "stats": deque(maxlen=50), # çµ±è¨ˆæƒ…å ±ã®æœ€å¤§ä¿æŒæ•°
    "is_generating": False,
    "stop_generation_requested": False,
})

STREAM_UPDATE_INTERVAL = 1.5
STREAM_UPDATE_CHARS = 75

script_dir = os.path.dirname(os.path.abspath(__file__))
prompts_dir_path = os.path.join(script_dir, PROMPT_DIR_NAME)

# Ollama API ã«æ¸¡ã™ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ç©ºæ–‡å­—åˆ—ã¯APIå´ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ã†æ„å›³)
DEFAULT_SYSTEM_PROMPT_TEXT = "" # ã‚‚ã—ãã¯ None ã§ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def get_prompt_name_from_content(prompt_content: str | None) -> str:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ã‹ã‚‰ã€å¯¾å¿œã™ã‚‹è¡¨ç¤ºåã‚’è¿”ã™"""
    if prompt_content is None or prompt_content == DEFAULT_SYSTEM_PROMPT_TEXT:
        return PROMPT_NAME_DEFAULT
    for name, content in available_prompts.items():
        if prompt_content == content:
            return name
    return "[ã‚«ã‚¹ã‚¿ãƒ è¨­å®š]" # ã“ã‚Œã¯é€šå¸¸ã€ç›´æ¥æ–‡å­—åˆ—ã§è¨­å®šã•ã‚ŒãŸå ´åˆãªã©ã‚’ç¤ºã™

# System prompt.txt ã®èª­ã¿è¾¼ã¿é–¢æ•°ã¯å‰Šé™¤

def _load_prompts_sync(dir_path: str) -> dict[str, str]:
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åŒæœŸçš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    loaded_prompts = {}
    logger.debug(f"_load_prompts_sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{dir_path}' ã®åŒæœŸèª­ã¿è¾¼ã¿ã‚’é–‹å§‹...")

    if not os.path.isdir(dir_path):
        logger.warning(f"_load_prompts_sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{dir_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return {}

    try:
        for filename in os.listdir(dir_path):
            if filename.lower().endswith(".txt"):
                file_path = os.path.join(dir_path, filename)
                prompt_name = os.path.splitext(filename)[0]
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read().strip()
                        if content:
                            # äºˆç´„èªã®ãƒã‚§ãƒƒã‚¯ã‚’ç°¡ç•¥åŒ–
                            if prompt_name == PROMPT_NAME_DEFAULT:
                                logger.warning(f"  - _sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå '{prompt_name}' ({filename}) ã¯äºˆç´„èªã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                                continue
                            loaded_prompts[prompt_name] = content
                            logger.debug(f"  - _sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ '{prompt_name}' ã‚’èª­ã¿è¾¼ã¿ã€‚")
                        else:
                            logger.warning(f"  - _sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ç©ºã€‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
                except Exception as e:
                    logger.error(f"  - _sync: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{filename}' èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}", exc_info=False)
    except Exception as e:
        logger.error(f"_sync: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{dir_path}' ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

    logger.debug(f"_load_prompts_sync: åŒæœŸèª­ã¿è¾¼ã¿å®Œäº†: {len(loaded_prompts)} å€‹ã€‚")
    return loaded_prompts

async def get_available_models() -> list[str]:
    """Ollama APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã‚’å–å¾—ã™ã‚‹"""
    url = f"{OLLAMA_API_URL}/api/tags"
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                if response.status == 200:
                    data = await response.json()
                    models = data.get('models', [])
                    return sorted([model['name'] for model in models])
                else:
                    logger.warning(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—APIã‚¨ãƒ©ãƒ¼ - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status}, URL: {url}")
                    return []
    except asyncio.TimeoutError:
        logger.error(f"Ollama API ({url}) ã¸ã®æ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (ãƒ¢ãƒ‡ãƒ«å–å¾—æ™‚)ã€‚")
        return []
    except aiohttp.ClientConnectorError as e:
        logger.error(f"Ollama APIã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ (ãƒ¢ãƒ‡ãƒ«å–å¾—æ™‚): {e}. URL: {url}")
        return []
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        return []

async def fetch_channel_history(channel: discord.TextChannel, limit: int = 100):
    """æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«ã®éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã—ã€å†…éƒ¨å±¥æ­´ã«è¿½åŠ ã™ã‚‹"""
    if not isinstance(channel, discord.TextChannel):
        logger.warning(f"æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«ãŒç„¡åŠ¹ã§ã™: {channel}")
        return

    channel_id = channel.id
    logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' (ID: {channel_id}) ã®å±¥æ­´å–å¾—ã‚’é–‹å§‹ (æœ€å¤§{limit}ä»¶)...")
    try:
        messages_to_add = []
        count = 0
        async for message in channel.history(limit=limit):
            if not message.author.bot or message.author.id == bot.user.id:
                if message.content:
                    messages_to_add.append({
                        "author_name": message.author.display_name,
                        "author_id": message.author.id,
                        "content": message.content,
                        "timestamp": message.created_at.isoformat(),
                        "is_bot": message.author.bot
                    })
                    count += 1

        added_count = 0
        history_deque = channel_data[channel_id]["history"]
        existing_timestamps_contents = { (msg["timestamp"], msg["content"]) for msg in history_deque }

        for msg in reversed(messages_to_add):
            if (msg["timestamp"], msg["content"]) not in existing_timestamps_contents:
                 history_deque.append(msg)
                 existing_timestamps_contents.add((msg["timestamp"], msg["content"]))
                 added_count += 1

        logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã‹ã‚‰ {count} ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª¿æŸ»ã—ã€{added_count} ä»¶ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¾ã—ãŸã€‚ç¾åœ¨ã®å±¥æ­´æ•°: {len(history_deque)}")

    except discord.Forbidden:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã®å±¥æ­´èª­ã¿å–ã‚Šæ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except discord.HTTPException as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã®å±¥æ­´å–å¾—ä¸­ã«Discord APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except Exception as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã®å±¥æ­´å–å¾—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)

def build_chat_context(channel_id: int) -> list[dict]:
    """æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«IDã®å†…éƒ¨å±¥æ­´ã‹ã‚‰ã€Ollama APIç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
    history_deque = channel_data[channel_id]["history"]
    messages = []
    for msg in history_deque:
        role = "assistant" if msg["is_bot"] and msg["author_id"] == bot.user.id else "user"
        messages.append({"role": role, "content": msg["content"]})
    return messages

async def generate_response_stream(
    prompt: str,
    channel_id: int,
    message_to_edit: discord.Message,
    model: str = None,
) -> tuple[str | None, dict | None, str | None]:
    """
    Ollama APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å¿œç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤ºã™ã‚‹ã€‚
    åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚Œã°ä¸­æ–­ã™ã‚‹ã€‚
    """
    current_model = model or active_model
    if not current_model:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å¿œç­”ç”Ÿæˆä¸å¯ - ãƒ¢ãƒ‡ãƒ«æœªè¨­å®š")
        return None, None, "ã‚¨ãƒ©ãƒ¼: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    channel_params = channel_data[channel_id]["params"]
    # system_prompts[current_model] ãŒ None ã®å ´åˆã¯ DEFAULT_SYSTEM_PROMPT_TEXT ã‚’ä½¿ç”¨
    system_prompt_content = system_prompts.get(current_model, None) or DEFAULT_SYSTEM_PROMPT_TEXT
    prompt_name = get_prompt_name_from_content(system_prompts.get(current_model))
    # using_custom = system_prompts.get(current_model) is not None # ã“ã®å¤‰æ•°ã¯ä½¿ã‚ã‚Œã¦ã„ãªã„ï¼Ÿ

    data = {
        "model": current_model,
        "prompt": prompt,
        "system": system_prompt_content,
        "stream": True,
        "options": channel_params,
    }
    url = f"{OLLAMA_API_URL}/api/generate"
    logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¢ãƒ‡ãƒ« '{current_model}' (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt_name}) ã«ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
    response_key = "response"
    done_key = "done"

    full_response = ""
    last_update_time = time.monotonic()
    last_update_len = 0
    performance_metrics = None
    error_message = None
    stopped_by_user = False
    start_time = time.monotonic()

    async def update_footer(status: str):
        if message_to_edit and message_to_edit.embeds:
            try:
                embed = message_to_edit.embeds[0]
                footer_text = f"Model: {current_model} | Prompt: {prompt_name} | {status}"
                embed.set_footer(text=footer_text)
                await message_to_edit.edit(embed=embed)
            except (discord.NotFound, discord.HTTPException):
                pass

    await update_footer("æ€è€ƒä¸­...")

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                url,
                json=data,
                timeout=aiohttp.ClientTimeout(total=600)
            ) as response:

                if response.status != 200:
                    error_text = await response.text()
                    logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: Ollama APIã‚¨ãƒ©ãƒ¼ ({response.status}): {error_text}")
                    return None, None, f"Ollama APIã‚¨ãƒ©ãƒ¼ ({response.status})ã€‚ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

                async for line in response.content:
                    if channel_data[channel_id]["stop_generation_requested"]:
                        logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã‚ˆã‚Šå¿œç­”ç”Ÿæˆåœæ­¢")
                        stopped_by_user = True
                        error_message = "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šå¿œç­”ç”ŸæˆãŒåœæ­¢ã•ã‚Œã¾ã—ãŸã€‚"
                        break

                    if line:
                        try:
                            chunk = json.loads(line.decode('utf-8'))
                            chunk_response_content = ""

                            if response_key in chunk and not chunk.get(done_key, False):
                                chunk_response_content = chunk[response_key]

                            if chunk_response_content:
                                full_response += chunk_response_content
                                current_time = time.monotonic()
                                if (current_time - last_update_time > STREAM_UPDATE_INTERVAL or
                                        len(full_response) - last_update_len > STREAM_UPDATE_CHARS):

                                    if message_to_edit and message_to_edit.embeds:
                                        display_response = full_response
                                        # Embed Description æ–‡å­—æ•°åˆ¶é™ (4096æœªæº€)
                                        if len(display_response) > 4000: # ã‚ˆã‚Šå®‰å…¨ãƒãƒ¼ã‚¸ãƒ³
                                            display_response = display_response[:4000] + "..."

                                        embed = message_to_edit.embeds[0]
                                        embed.description = display_response + " â–Œ"
                                        footer_text = f"Model: {current_model} | Prompt: {prompt_name} | ç”Ÿæˆä¸­..."
                                        embed.set_footer(text=footer_text)
                                        try:
                                            await message_to_edit.edit(embed=embed)
                                            last_update_time = current_time
                                            last_update_len = len(full_response)
                                        except discord.NotFound:
                                            logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç·¨é›†å¤±æ•— - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¶ˆå¤±")
                                            message_to_edit = None
                                            error_message = "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã«å†…éƒ¨ã‚¨ãƒ©ãƒ¼ (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¶ˆå¤±)ã€‚"
                                            break
                                        except discord.HTTPException as e:
                                            logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç·¨é›†å¤±æ•—: {e}")

                            if chunk.get(done_key, False):
                                end_time = time.monotonic()
                                total_duration = end_time - start_time
                                metrics_data = {
                                    "total_duration": total_duration,
                                    "load_duration_sec": chunk.get('load_duration', 0) / 1e9,
                                    "prompt_eval_count": chunk.get('prompt_eval_count', 0),
                                    "prompt_eval_duration_sec": chunk.get('prompt_eval_duration', 0) / 1e9,
                                    "eval_count": chunk.get('eval_count', 0),
                                    "eval_duration_sec": chunk.get('eval_duration', 0) / 1e9
                                }
                                eval_duration = metrics_data["eval_duration_sec"]
                                eval_count = metrics_data["eval_count"]
                                if eval_duration > 0 and eval_count > 0:
                                    tps = eval_count / eval_duration
                                    metrics_data["tokens_per_second"] = tps if not math.isnan(tps) else 0.0
                                else:
                                    metrics_data["tokens_per_second"] = 0.0
                                metrics_data["total_tokens"] = eval_count if not math.isnan(eval_count) else 0

                                performance_metrics = metrics_data
                                logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ç”Ÿæˆå®Œäº† ({total_duration:.2f}s). ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {performance_metrics.get('tokens_per_second', 0):.2f} tok/s, {performance_metrics.get('total_tokens', 0)} tokens.")
                                break

                        except json.JSONDecodeError as e:
                            logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: JSONè§£æå¤±æ•—: {e}. Line: {line.decode('utf-8', errors='ignore')}")
                        except Exception as e:
                             logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                             error_message = "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‚"
                             break

                if stopped_by_user:
                    performance_metrics = None # ä¸å®Œå…¨ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã‚¯ãƒªã‚¢

    except asyncio.TimeoutError:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: Ollama APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        error_message = "ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚Ollamaã‚µãƒ¼ãƒãƒ¼ç¢ºèªè¦ã€‚"
    except aiohttp.ClientConnectorError as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: Ollama APIæ¥ç¶šå¤±æ•—: {e}")
        error_message = f"Ollama API ({OLLAMA_API_URL}) æ¥ç¶šä¸å¯ã€‚ã‚µãƒ¼ãƒãƒ¼ç¢ºèªè¦ã€‚"
    except Exception as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: Ollama APIãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        error_message = f"å¿œç­”ç”Ÿæˆä¸­ã‚¨ãƒ©ãƒ¼: {str(e)}"

    return full_response.strip(), performance_metrics, error_message

# --- å®šæœŸå®Ÿè¡Œã‚¿ã‚¹ã‚¯ ---

@tasks.loop(minutes=PROMPT_RELOAD_INTERVAL_MINUTES)
async def reload_prompts_task():
    global available_prompts
    logger.info("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šæœŸãƒªãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ...")
    try:
        # _load_prompts_sync ã‹ã‚‰ä¸è¦ãªå¼•æ•°ã‚’å‰Šé™¤
        new_prompts = await bot.loop.run_in_executor(
            None,
            functools.partial(_load_prompts_sync, prompts_dir_path)
        )
        if new_prompts != available_prompts:
            added = list(set(new_prompts.keys()) - set(available_prompts.keys()))
            removed = list(set(available_prompts.keys()) - set(new_prompts.keys()))
            updated = [k for k, v in new_prompts.items() if k in available_prompts and available_prompts[k] != v]
            available_prompts = new_prompts
            log_msg = f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªã‚¹ãƒˆæ›´æ–° ({len(available_prompts)}å€‹)ã€‚"
            if added: log_msg += f" è¿½åŠ : {added}"
            if removed: log_msg += f" å‰Šé™¤: {removed}"
            if updated: log_msg += f" æ›´æ–°: {updated}"
            logger.info(log_msg)
        else:
            logger.info("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ãªã—ã€‚")
    except Exception as e:
        logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

@reload_prompts_task.before_loop
async def before_reload_prompts():
    await bot.wait_until_ready()
    logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯æº–å‚™å®Œäº† ({PROMPT_RELOAD_INTERVAL_MINUTES}åˆ†ã”ã¨)ã€‚")
    # åˆå›èª­ã¿è¾¼ã¿ã¯ on_ready ã§è¡Œã†
    await reload_prompts_task() # åˆå›å®Ÿè¡Œ

@tasks.loop(minutes=MODEL_UPDATE_INTERVAL_MINUTES)
async def update_models_task():
    global available_ollama_models
    logger.info("ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå®šæœŸæ›´æ–°å®Ÿè¡Œ...")
    try:
        models = await get_available_models()
        if models != available_ollama_models:
            available_ollama_models = models
            logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆæ›´æ–° ({len(available_ollama_models)}å€‹): {available_ollama_models}")
        else:
            logger.info("ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå¤‰æ›´ãªã—ã€‚")
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°ã‚¿ã‚¹ã‚¯ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

@update_models_task.before_loop
async def before_update_models():
    await bot.wait_until_ready()
    logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°ã‚¿ã‚¹ã‚¯æº–å‚™å®Œäº† ({MODEL_UPDATE_INTERVAL_MINUTES}åˆ†ã”ã¨)ã€‚åˆå›æ›´æ–°å®Ÿè¡Œ...")
    await update_models_task() # åˆå›å®Ÿè¡Œ

# --- Discord ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ© ---

@bot.event
async def on_ready():
    """BOTèµ·å‹•æ™‚ã®å‡¦ç†"""
    logger.info(f'{bot.user} (ID: {bot.user.id}) ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ')

    # System prompt.txt ã®èª­ã¿è¾¼ã¿å‡¦ç†ã‚’å‰Šé™¤

    global active_model
    if not active_model:
        logger.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«æœªè¨­å®šã€‚åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è‡ªå‹•é¸æŠè©¦è¡Œ...")
        initial_models = await get_available_models()
        if initial_models:
            active_model = initial_models[0]
            available_ollama_models[:] = initial_models # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚æ›´æ–°
            logger.info(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ‡ãƒ«ã‚’ '{active_model}' ã«è¨­å®šã—ã¾ã—ãŸã€‚")
        else:
            logger.error("åˆ©ç”¨å¯èƒ½ãªOllamaãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`/model` ã‚³ãƒãƒ³ãƒ‰ã§æ‰‹å‹•è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
    elif not available_ollama_models: # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã¯ã‚ã‚‹ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆ
         available_ollama_models[:] = await get_available_models()
         logger.info(f"åˆå›ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–° ({len(available_ollama_models)}å€‹)ã€‚")

    # åˆå›ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿
    global available_prompts
    try:
        available_prompts = await bot.loop.run_in_executor(
            None,
            functools.partial(_load_prompts_sync, prompts_dir_path)
        )
        logger.info(f"åˆå›ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿å®Œäº† ({len(available_prompts)}å€‹): {list(available_prompts.keys())}")
    except Exception as e:
        logger.error(f"åˆå›ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ None (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) ã«è¨­å®š
    if active_model and active_model not in system_prompts:
         system_prompts[active_model] = None

    chat_channel = bot.get_channel(CHAT_CHANNEL_ID)
    if chat_channel and isinstance(chat_channel, discord.TextChannel):
        logger.info(f"ãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ« '{chat_channel.name}' (ID: {CHAT_CHANNEL_ID}) èªè­˜ã€‚å±¥æ­´èª­ã¿è¾¼ã¿é–‹å§‹...")
        await fetch_channel_history(chat_channel, limit=HISTORY_LIMIT * 2)
    else:
        logger.error(f"æŒ‡å®šãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ID ({CHAT_CHANNEL_ID}) ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    try:
        synced = await bot.tree.sync()
        logger.info(f'{len(synced)}å€‹ã®ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰åŒæœŸå®Œäº†: {[cmd.name for cmd in synced]}')
    except Exception as e:
        logger.error(f"ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

    # ã‚¿ã‚¹ã‚¯ã®é–‹å§‹ã¯ on_ready å†…ã§è¡Œã†ï¼ˆbefore_loop ã¯ä¸è¦ã«ãªã‚‹å ´åˆã‚‚ã‚ã‚‹ãŒã€å®‰å…¨ã®ãŸã‚æ®‹ã™ï¼‰
    if not reload_prompts_task.is_running():
        reload_prompts_task.start()
    if not update_models_task.is_running():
        update_models_task.start()

    logger.info("BOTã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


@bot.event
async def on_message(message: discord.Message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡æ™‚ã®å‡¦ç†"""
    if message.author == bot.user or message.channel.id != CHAT_CHANNEL_ID or message.content.startswith('/') or message.content.startswith(bot.command_prefix):
        return

    channel_id = message.channel.id

    if channel_data[channel_id]["is_generating"]:
        try:
            # fail_if_not_exists ã‚’å‰Šé™¤
            await message.reply("â³ ä»–ã®å¿œç­”ã‚’ç”Ÿæˆä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚", mention_author=False, delete_after=10)
        except discord.HTTPException:
            pass
        logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å¿œç­”ç”Ÿæˆä¸­ã«æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ã€ã‚¹ã‚­ãƒƒãƒ—: {message.content[:50]}...")
        return

    current_model = active_model
    if not current_model:
        try:
            await message.reply("âš ï¸ ãƒ¢ãƒ‡ãƒ«æœªé¸æŠã€‚`/model` ã‚³ãƒãƒ³ãƒ‰ã§é¸æŠã—ã¦ãã ã•ã„ã€‚", mention_author=False)
        except discord.HTTPException: pass
        return

    user_message_data = {
        "author_name": message.author.display_name,
        "author_id": message.author.id,
        "content": message.content,
        "timestamp": message.created_at.isoformat(),
        "is_bot": False
    }
    channel_data[channel_id]["history"].append(user_message_data)
    logger.debug(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id} å±¥æ­´è¿½åŠ  (User): {user_message_data['author_name']} - {user_message_data['content'][:50]}...")

    reply_message = None
    final_response_text = None # finally ãƒ–ãƒ­ãƒƒã‚¯ã§å‚ç…§ã§ãã‚‹ã‚ˆã†åˆæœŸåŒ–
    metrics = None
    error_msg = None
    try:
        channel_data[channel_id]["is_generating"] = True
        channel_data[channel_id]["stop_generation_requested"] = False

        prompt_name = get_prompt_name_from_content(system_prompts.get(current_model))
        placeholder_embed = Embed(description="æ€è€ƒä¸­... ğŸ¤”", color=discord.Color.light_gray())
        placeholder_embed.set_footer(text=f"Model: {current_model} | Prompt: {prompt_name}")
        reply_message = await message.reply(embed=placeholder_embed, mention_author=False)

        final_response_text, metrics, error_msg = await generate_response_stream(
            prompt=message.content,
            channel_id=channel_id,
            message_to_edit=reply_message,
            model=current_model
        )

    except discord.HTTPException as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†/ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        error_msg = f"å‡¦ç†ä¸­ã«Discord APIã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ:\n```\n{e}\n```" # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ finaly ã§ä½¿ãˆã‚‹ã‚ˆã†ã«æ ¼ç´
    except Exception as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        error_msg = "å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚" # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ finaly ã§ä½¿ãˆã‚‹ã‚ˆã†ã«æ ¼ç´
    finally:
        channel_data[channel_id]["is_generating"] = False
        channel_data[channel_id]["stop_generation_requested"] = False
        logger.debug(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: is_generating ãƒ•ãƒ©ã‚°ã‚’ False ã«ãƒªã‚»ãƒƒãƒˆã€‚")

    # finally ãƒ–ãƒ­ãƒƒã‚¯ã®å¾Œã§æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†ã‚’è¡Œã†
    if reply_message:
        try:
            final_embed = reply_message.embeds[0] if reply_message.embeds else Embed()
            prompt_name = get_prompt_name_from_content(system_prompts.get(current_model)) # ã“ã“ã§ã‚‚å–å¾—

            if error_msg:
                if "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šå¿œç­”ç”ŸæˆãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ" in error_msg:
                    final_embed.title = "â¹ï¸ åœæ­¢"
                    stopped_text = final_response_text if final_response_text else '(å¿œç­”ãªã—)'
                    if len(stopped_text) > 4000: stopped_text = stopped_text[:4000] + "...(é€”ä¸­çœç•¥)"
                    final_embed.description = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã‚ˆã‚Šå¿œç­”åœæ­¢ã€‚\n\n**ç”Ÿæˆé€”ä¸­å†…å®¹:**\n{stopped_text}"
                    final_embed.color = discord.Color.orange()
                    logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¦ãƒ¼ã‚¶ãƒ¼åœæ­¢å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã€‚")
                else:
                    final_embed.title = "âš ï¸ ã‚¨ãƒ©ãƒ¼"
                    final_embed.description = f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n\n{error_msg}"
                    final_embed.color = discord.Color.red()
                final_embed.set_footer(text=f"Model: {current_model} | Prompt: {prompt_name}")

            elif final_response_text is not None: # None ã§ãªã„ã“ã¨ã‚’ç¢ºèª
                final_embed.title = None
                display_final_text = final_response_text
                if len(display_final_text) > 4000: display_final_text = display_final_text[:4000] + "\n...(æ–‡å­—æ•°ä¸Šé™)"
                final_embed.description = display_final_text if display_final_text else "(ç©ºã®å¿œç­”)" # ç©ºå¿œç­”ã®å ´åˆã‚‚è¡¨ç¤º
                final_embed.color = discord.Color.blue()

                footer_text = f"Model: {current_model} | Prompt: {prompt_name}"
                if metrics:
                    channel_data[channel_id]["stats"].append(metrics)
                    tok_sec = metrics.get("tokens_per_second", 0)
                    total_tokens = metrics.get("total_tokens", 0)
                    duration = metrics.get("total_duration", 0)
                    if tok_sec > 0: footer_text += f" | {tok_sec:.2f} tok/s"
                    if total_tokens > 0: footer_text += f" | {int(total_tokens)} tokens"
                    if duration > 0: footer_text += f" | {duration:.2f}s"
                final_embed.set_footer(text=footer_text)

                # å±¥æ­´ã«ã¯å®Œå…¨ãªå¿œç­”ã‚’ä¿å­˜
                bot_message_data = {
                    "author_name": bot.user.display_name,
                    "author_id": bot.user.id,
                    "content": final_response_text,
                    "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat(),
                    "is_bot": True
                }
                channel_data[channel_id]["history"].append(bot_message_data)
                logger.debug(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id} å±¥æ­´è¿½åŠ  (Bot): {bot_message_data['author_name']} - {bot_message_data['content'][:50]}...")
            else:
                # generate_response_stream ãŒ (None, None, None) ã‚’è¿”ã—ãŸå ´åˆãªã©
                final_embed.title = "â“ ç„¡å¿œç­”"
                final_embed.description = "å¿œç­”ç”Ÿæˆå¤±æ•—ã€‚å…¥åŠ›ç¢ºèªã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«å¤‰æ›´è©¦è¡Œè¦ã€‚"
                final_embed.color = discord.Color.orange()
                final_embed.set_footer(text=f"Model: {current_model} | Prompt: {prompt_name}")
                logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚ãªã—ã€‚")

            await reply_message.edit(embed=final_embed)

        except discord.NotFound:
             logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†å¤±æ•— - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¶ˆå¤± (ID: {reply_message.id})")
        except discord.HTTPException as e:
            logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†å¤±æ•—: {e}")
            err_code = getattr(e, 'code', 'N/A')
            err_text = str(e)[:100]
            try:
                await message.channel.send(f"ã‚¨ãƒ©ãƒ¼: å¿œç­”æœ€çµ‚è¡¨ç¤ºå¤±æ•— (Code: {err_code}) - {err_text}", reference=message, mention_author=False)
            except discord.HTTPException: pass
        except IndexError:
             logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†å¤±æ•— - Embedãªã—")
             try: await reply_message.edit(content="ã‚¨ãƒ©ãƒ¼: å¿œç­”è¡¨ç¤ºæº–å‚™å¤±æ•—ã€‚", embed=None)
             except discord.HTTPException: pass
        except Exception as e:
            logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç·¨é›†ä¸­äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            try: await reply_message.edit(content="ã‚¨ãƒ©ãƒ¼: å¿œç­”æœ€çµ‚è¡¨ç¤ºä¸­ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€‚", embed=None)
            except discord.HTTPException: pass

# --- ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰ ---

# --- ã‚ªãƒ¼ãƒˆã‚³ãƒ³ãƒ—ãƒªãƒ¼ãƒˆ ---
async def model_autocomplete(interaction: discord.Interaction, current: str) -> list[app_commands.Choice[str]]:
    choices = [
        app_commands.Choice(name=model, value=model)
        for model in available_ollama_models if current.lower() in model.lower()
    ]
    return choices[:25]

async def prompt_autocomplete(interaction: discord.Interaction, current: str) -> list[app_commands.Choice[str]]:
    choices = []
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠè‚¢ã‚’è¿½åŠ 
    if current.lower() in PROMPT_NAME_DEFAULT.lower():
        choices.append(app_commands.Choice(name=PROMPT_NAME_DEFAULT, value=PROMPT_NAME_DEFAULT))

    # System prompt.txt ã®é¸æŠè‚¢ã¯å‰Šé™¤

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠè‚¢ã‚’è¿½åŠ 
    custom_choices = [
        app_commands.Choice(name=name, value=name)
        for name in sorted(available_prompts.keys()) if current.lower() in name.lower()
    ]
    choices.extend(custom_choices)
    return choices[:25]

# --- ã‚³ãƒãƒ³ãƒ‰æœ¬ä½“ ---

@bot.tree.command(name="stop", description="ç¾åœ¨ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ç”Ÿæˆä¸­ã®AIã®å¿œç­”ã‚’åœæ­¢ã—ã¾ã™ã€‚")
async def stop_generation(interaction: discord.Interaction):
    channel_id = interaction.channel_id
    if channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    # defer() ã¯ä¸è¦ï¼ˆã™ãã«å®Œäº†ã™ã‚‹ãŸã‚ï¼‰
    if channel_data[channel_id]["is_generating"]:
        if not channel_data[channel_id]["stop_generation_requested"]:
            channel_data[channel_id]["stop_generation_requested"] = True
            logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¦ãƒ¼ã‚¶ãƒ¼ {interaction.user} (ID: {interaction.user.id}) ã«ã‚ˆã‚Šåœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€‚")
            await interaction.response.send_message("â¹ï¸ å¿œç­”ã®åœæ­¢ã‚’è©¦ã¿ã¦ã„ã¾ã™...", ephemeral=True)
            try:
                # ãƒãƒ£ãƒ³ãƒãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰é€ä¿¡
                if interaction.channel:
                    await interaction.channel.send(f"âš ï¸ {interaction.user.mention} ãŒå¿œç­”ç”Ÿæˆã®åœæ­¢ã‚’è©¦ã¿ã¦ã„ã¾ã™ã€‚")
                else:
                    logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: åœæ­¢è©¦è¡Œã®å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•— - interaction.channel is None")
            except discord.HTTPException as e:
                 logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: åœæ­¢è©¦è¡Œã®å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•—: {e}")
        else:
            await interaction.response.send_message("â„¹ï¸ æ—¢ã«åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒé€ä¿¡ã•ã‚Œã¦ã„ã¾ã™ã€‚", ephemeral=True)
    else:
        await interaction.response.send_message("â„¹ï¸ ç¾åœ¨ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ç”Ÿæˆä¸­ã®å¿œç­”ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚", ephemeral=True)


@bot.tree.command(name="model", description="ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚")
@app_commands.describe(
    model="åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«åã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
    # prompt_name ã®èª¬æ˜æ–‡ã‹ã‚‰ [System prompt.txt] ã‚’å‰Šé™¤
    prompt_name=f"é©ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ('{PROMPT_DIR_NAME}'å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã€{PROMPT_NAME_DEFAULT})"
)
@app_commands.autocomplete(model=model_autocomplete, prompt_name=prompt_autocomplete)
async def select_model(interaction: discord.Interaction, model: str, prompt_name: str = None):
    global active_model
    channel_id = interaction.channel_id
    if channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    if model not in available_ollama_models:
        model_list_str = "\n- ".join(available_ollama_models) if available_ollama_models else "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        await interaction.followup.send(
            f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ« '{model}' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‚ç…§)ã€‚\nåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ« (ã‚­ãƒ£ãƒƒã‚·ãƒ¥):\n- {model_list_str}",
            ephemeral=True
        )
        return

    previous_model = active_model
    previous_prompt_content = system_prompts.get(previous_model)
    previous_prompt_name = get_prompt_name_from_content(previous_prompt_content)

    active_model = model
    model_changed = previous_model != active_model

    prompt_actually_changed = False
    selected_prompt_name_for_log = None # ãƒ­ã‚°è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå
    error_occurred = False
    ephemeral_message_lines = []

    if prompt_name:
        new_prompt_content: str | None = None
        valid_prompt_selection = False
        selected_prompt_name_for_log = prompt_name # ã¾ãšé¸æŠã•ã‚ŒãŸåå‰ã‚’ä»®ä»£å…¥

        if prompt_name == PROMPT_NAME_DEFAULT:
             new_prompt_content = None # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None
             valid_prompt_selection = True
        # System prompt.txt ã®åˆ†å²ã¯å‰Šé™¤
        elif prompt_name in available_prompts:
             new_prompt_content = available_prompts[prompt_name]
             valid_prompt_selection = True
        else:
             ephemeral_message_lines.append(f"âŒ ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå '{prompt_name}'ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã‚¹ã‚­ãƒƒãƒ—ã€‚")
             selected_prompt_name_for_log = None # ã‚¨ãƒ©ãƒ¼ãªã®ã§ãƒ­ã‚°ç”¨åå‰ã‚’ãƒªã‚»ãƒƒãƒˆ
             error_occurred = True

        if valid_prompt_selection:
            current_prompt_for_new_model = system_prompts.get(active_model)
            if new_prompt_content != current_prompt_for_new_model:
                system_prompts[active_model] = new_prompt_content
                logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¢ãƒ‡ãƒ« '{active_model}' ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š -> '{prompt_name}'")
                prompt_actually_changed = True
                ephemeral_message_lines.append(f"ğŸ“„ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ **{prompt_name}** ã«è¨­å®šã€‚")
            else:
                 ephemeral_message_lines.append(f"â„¹ï¸ ãƒ¢ãƒ‡ãƒ« **{active_model}** ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ—¢ã« **{prompt_name}**ã€‚")
    else:
        # prompt_name ãŒæŒ‡å®šã•ã‚Œãªã‹ã£ãŸå ´åˆã€ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ™‚ã¯ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®šã‚’å¼•ãç¶™ã
        maintained_prompt_content = system_prompts.get(active_model) # å¤‰æ›´å¾Œã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        selected_prompt_name_for_log = get_prompt_name_from_content(maintained_prompt_content)
        ephemeral_message_lines.append(f"â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ **{selected_prompt_name_for_log}** ç¶­æŒã€‚")
        # ãƒ¢ãƒ‡ãƒ«ãŒåˆã‚ã¦ä½¿ã‚ã‚Œã‚‹å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(None)ãŒè¨­å®šã•ã‚Œã‚‹
        if active_model not in system_prompts:
            system_prompts[active_model] = None

    final_ephemeral_message = []
    if model_changed: final_ephemeral_message.append(f"âœ… ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ -> **{active_model}**ã€‚")
    else: final_ephemeral_message.append(f"â„¹ï¸ ãƒ¢ãƒ‡ãƒ«ã¯ **{active_model}** ã®ã¾ã¾ã€‚")
    final_ephemeral_message.extend(ephemeral_message_lines)

    await interaction.followup.send("\n".join(final_ephemeral_message), ephemeral=True)

    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿å…¬é–‹ãƒ­ã‚°ã‚’é€ä¿¡
    if not error_occurred and (model_changed or prompt_actually_changed):
        log_parts = []
        # ãƒ­ã‚°è¡¨ç¤ºç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåã‚’ç¢ºå®šã•ã›ã‚‹
        final_prompt_name = get_prompt_name_from_content(system_prompts.get(active_model))
        current_model_display = f"**{active_model}**"
        current_prompt_display = f"**{final_prompt_name}**"

        if model_changed and prompt_actually_changed: log_parts.append(f"ãƒ¢ãƒ‡ãƒ«: **{previous_model}** â†’ {current_model_display}, ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: **{previous_prompt_name}** â†’ {current_prompt_display}")
        elif model_changed: log_parts.append(f"ãƒ¢ãƒ‡ãƒ«: **{previous_model}** â†’ {current_model_display} (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {current_prompt_display})")
        elif prompt_actually_changed: log_parts.append(f"ãƒ¢ãƒ‡ãƒ« {current_model_display} ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: **{previous_prompt_name}** â†’ {current_prompt_display}")

        if log_parts:
            public_log_message = f"ğŸ”§ {interaction.user.mention} è¨­å®šå¤‰æ›´: {' '.join(log_parts)}"
            try:
                if interaction.channel: await interaction.channel.send(public_log_message)
                else: logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•— - interaction.channel is None")
            except discord.HTTPException as e: logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¢ãƒ‡ãƒ«å¤‰æ›´å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•—: {e}")


@bot.tree.command(name="set_prompt", description="ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¢ãƒ‡ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚")
@app_commands.describe(
    # prompt_name ã®èª¬æ˜æ–‡ã‹ã‚‰ [System prompt.txt] ã‚’å‰Šé™¤
    prompt_name=f"é©ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ('{PROMPT_DIR_NAME}'å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã€{PROMPT_NAME_DEFAULT})"
)
@app_commands.autocomplete(prompt_name=prompt_autocomplete)
async def set_prompt(interaction: discord.Interaction, prompt_name: str):
    channel_id = interaction.channel_id
    if channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return
    if not active_model:
        await interaction.response.send_message("âš ï¸ ãƒ¢ãƒ‡ãƒ«æœªé¸æŠã€‚`/model` ã‚³ãƒãƒ³ãƒ‰ã§é¸æŠã—ã¦ãã ã•ã„ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    previous_prompt_content = system_prompts.get(active_model)
    previous_prompt_name = get_prompt_name_from_content(previous_prompt_content)
    new_prompt_content: str | None = None
    valid_prompt = False
    error_message = None

    if prompt_name == PROMPT_NAME_DEFAULT:
        new_prompt_content = None # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None
        valid_prompt = True
    # System prompt.txt ã®åˆ†å²ã¯å‰Šé™¤
    elif prompt_name in available_prompts:
        new_prompt_content = available_prompts[prompt_name]
        valid_prompt = True
    else:
        error_message = f"âŒ ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå '{prompt_name}'ã€‚"

    if error_message:
        await interaction.followup.send(error_message, ephemeral=True)
        return

    if valid_prompt:
        if new_prompt_content != previous_prompt_content:
            system_prompts[active_model] = new_prompt_content
            logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ¢ãƒ‡ãƒ« '{active_model}' ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ -> '{prompt_name}'")
            await interaction.followup.send(f"âœ… ãƒ¢ãƒ‡ãƒ« **{active_model}** ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š -> **{prompt_name}**ã€‚", ephemeral=True)

            public_log_message = f"ğŸ”§ {interaction.user.mention} ãŒãƒ¢ãƒ‡ãƒ« **{active_model}** ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´: **{previous_prompt_name}** â†’ **{prompt_name}**"
            try:
                if interaction.channel: await interaction.channel.send(public_log_message)
                else: logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•— - interaction.channel is None")
            except discord.HTTPException as e: logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {channel_id}: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´å…¬é–‹ãƒ­ã‚°é€ä¿¡å¤±æ•—: {e}")
        else:
            await interaction.followup.send(f"â„¹ï¸ ãƒ¢ãƒ‡ãƒ« **{active_model}** ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯æ—¢ã« **{prompt_name}**ã€‚", ephemeral=True)


@bot.tree.command(name="clear_history", description="ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®ä¼šè©±å±¥æ­´ã¨å¿œç­”çµ±è¨ˆã‚’æ¶ˆå»ã—ã¾ã™ã€‚")
async def clear_history(interaction: discord.Interaction):
    target_channel_id = interaction.channel_id
    if target_channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    if target_channel_id in channel_data:
        channel_data[target_channel_id]["history"].clear()
        channel_data[target_channel_id]["stats"].clear()
        logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ«ID {target_channel_id} ä¼šè©±å±¥æ­´/çµ±è¨ˆã‚¯ãƒªã‚¢å®Œäº†ã€‚")
        await interaction.followup.send("âœ… ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®ä¼šè©±å±¥æ­´ã¨å¿œç­”çµ±è¨ˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚", ephemeral=True)
    else:
        # channel_data ã¯ defaultdict ãªã®ã§ã€ã“ã®ãƒ‘ã‚¹ã¯é€šå¸¸é€šã‚‰ãªã„ã¯ãšã ãŒå¿µã®ãŸã‚
        logger.warning(f"ã‚¯ãƒªã‚¢å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ID {target_channel_id} ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
        await interaction.followup.send("â„¹ï¸ ã‚¯ãƒªã‚¢å¯¾è±¡ã®ä¼šè©±å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", ephemeral=True)


@bot.tree.command(name="show_history", description="ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
@app_commands.describe(count=f"è¡¨ç¤ºã™ã‚‹å±¥æ­´ã®ä»¶æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10, æœ€å¤§ {HISTORY_LIMIT})")
async def show_history(interaction: discord.Interaction, count: app_commands.Range[int, 1, None] = 10):
    target_channel_id = interaction.channel_id
    if target_channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    history = channel_data[target_channel_id]["history"]
    if not history:
        await interaction.followup.send("è¡¨ç¤ºã§ãã‚‹ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", ephemeral=True)
        return

    actual_count = min(count, HISTORY_LIMIT, len(history)) # å±¥æ­´æ•°ã‚‚è€ƒæ…®
    history_list = list(history)
    start_index = max(0, len(history_list) - actual_count)
    display_history = history_list[start_index:]

    embed = Embed(title=f"ç›´è¿‘ä¼šè©±å±¥æ­´ ({len(display_history)}/{len(history_list)}ä»¶)", color=discord.Color.light_gray())
    history_text = ""
    for i, msg in enumerate(display_history):
        prefix = "ğŸ¤–" if msg["is_bot"] else "ğŸ‘¤"
        author_name_safe = discord.utils.escape_markdown(msg['author_name'])
        author_str = f"{prefix} **{'Assistant' if msg['is_bot'] else author_name_safe}**"
        content_short = (msg['content'][:150] + '...') if len(msg['content']) > 150 else msg['content']
        # Discordã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ãŒå¿…è¦ãªæ–‡å­—ã‚’å‡¦ç†
        content_safe = discord.utils.escape_markdown(content_short).replace('`', '\\`')
        entry_text = f"`{start_index + i + 1}`. {author_str}:\n{content_safe}\n\n"

        if len(history_text) + len(entry_text) > 4000: # Embed Description ã®åˆ¶é™
             history_text += "... (è¡¨ç¤ºæ•°ä¸Šé™ã®ãŸã‚çœç•¥)"
             break
        history_text += entry_text

    embed.description = history_text if history_text else "å±¥æ­´å†…å®¹ç©ºã€‚"
    embed.set_footer(text=f"æœ€å¤§ä¿æŒæ•°: {HISTORY_LIMIT}ä»¶")
    await interaction.followup.send(embed=embed, ephemeral=True)


@bot.tree.command(name="set_param", description="Ollamaã®ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (temperature, top_k, top_p) ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
@app_commands.describe(parameter="èª¿æ•´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å", value="è¨­å®šã™ã‚‹å€¤ (ä¾‹: 0.7, 50)")
@app_commands.choices(parameter=[
    app_commands.Choice(name="temperature", value="temperature"),
    app_commands.Choice(name="top_k", value="top_k"),
    app_commands.Choice(name="top_p", value="top_p"),
])
async def set_parameter(interaction: discord.Interaction, parameter: app_commands.Choice[str], value: str):
    target_channel_id = interaction.channel_id
    if target_channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    param_name = parameter.value
    current_params = channel_data[target_channel_id]["params"]
    response_message = ""

    try:
        original_value = current_params.get(param_name)
        new_value = None

        # å€¤ã®æ¤œè¨¼ã¨å¤‰æ›
        if param_name == "temperature":
            try:
                float_value = float(value)
                if 0.0 <= float_value <= 2.0:
                    new_value = float_value
                else:
                    raise ValueError("Temperature ã¯ 0.0 ã‹ã‚‰ 2.0 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            except ValueError:
                raise ValueError("Temperature ã«ã¯æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif param_name == "top_k":
            try:
                int_value = int(value)
                if int_value >= 0:
                    new_value = int_value
                else:
                    raise ValueError("Top K ã¯ 0 ä»¥ä¸Šã®æ•´æ•°ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            except ValueError:
                 raise ValueError("Top K ã«ã¯æ•´æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif param_name == "top_p":
            try:
                float_value = float(value)
                if 0.0 <= float_value <= 1.0:
                     new_value = float_value
                else:
                    raise ValueError("Top P ã¯ 0.0 ã‹ã‚‰ 1.0 ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            except ValueError:
                raise ValueError("Top P ã«ã¯æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        if new_value is not None:
            # å€¤ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯ (æµ®å‹•å°æ•°ç‚¹æ•°ã®æ¯”è¼ƒã‚‚è€ƒæ…®)
            is_changed = not (isinstance(original_value, (int, float)) and isinstance(new_value, (int, float)) and math.isclose(original_value, new_value, rel_tol=1e-9)) and original_value != new_value

            if is_changed:
                 current_params[param_name] = new_value
                 logger.info(f"ãƒãƒ£ãƒ³ãƒãƒ« {target_channel_id}: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ '{param_name}' è¨­å®š -> '{new_value}'")
                 response_message = f"âœ… ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ **{param_name}** è¨­å®š -> **{new_value}**ã€‚"
            else:
                # å€¤ã¯æ­£ã—ã„ãŒå¤‰æ›´ãŒãªã„å ´åˆ
                 response_message = f"â„¹ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ **{param_name}** ã¯æ—¢ã« **{new_value}**ã€‚"
        else:
             # ã“ã®ãƒ‘ã‚¹ã«ã¯é€šå¸¸åˆ°é”ã—ãªã„ã¯ãš
             raise ValueError("å†…éƒ¨ã‚¨ãƒ©ãƒ¼: å€¤ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    except ValueError as e:
        logger.warning(f"ãƒãƒ£ãƒ³ãƒãƒ« {target_channel_id}: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚¨ãƒ©ãƒ¼ ({param_name}={value}): {e}")
        response_message = f"âš ï¸ è¨­å®šå€¤ã‚¨ãƒ©ãƒ¼: {e}"
    except Exception as e:
        logger.error(f"ãƒãƒ£ãƒ³ãƒãƒ« {target_channel_id}: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šä¸­ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        response_message = "âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

    await interaction.followup.send(response_message, ephemeral=True)


@bot.tree.command(name="stats", description="ç¾åœ¨ã®è¨­å®šã¨ç›´è¿‘ã®å¿œç­”ç”Ÿæˆçµ±è¨ˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
async def show_stats(interaction: discord.Interaction):
    target_channel_id = interaction.channel_id
    if target_channel_id != CHAT_CHANNEL_ID:
        await interaction.response.send_message("ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚", ephemeral=True)
        return

    await interaction.response.defer(ephemeral=True, thinking=False)

    stats_deque = channel_data[target_channel_id]["stats"]
    total_count = len(stats_deque)
    stats_max_len = channel_data[target_channel_id]["stats"].maxlen or 50 # maxlen ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã‚’è€ƒæ…®

    embed = Embed(title="ğŸ“Š BOTã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ & å¿œç­”çµ±è¨ˆ", color=discord.Color.green())

    current_model_str = f"**{active_model}**" if active_model else "æœªè¨­å®š"
    current_prompt_content = system_prompts.get(active_model)
    current_prompt_name = get_prompt_name_from_content(current_prompt_content)
    current_prompt_str = f"**{current_prompt_name}**"
    current_params = channel_data[target_channel_id]["params"]
    params_str = ", ".join([f"{k}={v}" for k, v in sorted(current_params.items())]) if current_params else "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"

    embed.add_field(
        name="ç¾åœ¨ã®è¨­å®š",
        value=f"ãƒ¢ãƒ‡ãƒ«: {current_model_str}\nãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {current_prompt_str}\nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: `{params_str}`",
        inline=False
    )

    if not stats_deque:
        embed.add_field(name=f"å¿œç­”çµ±è¨ˆ (ç›´è¿‘ 0/{stats_max_len} å›)", value="è¨˜éŒ²ãªã—ã€‚", inline=False)
    else:
        total_duration, total_tokens, total_tps, valid_tps_count = 0.0, 0, 0.0, 0
        for stat in stats_deque:
            # get ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ 0.0 ã‚„ 0 ã«ã—ã¦ None ã®å¯èƒ½æ€§ã‚’æ’é™¤
            duration = stat.get("total_duration", 0.0)
            tokens = stat.get("total_tokens", 0)
            tps = stat.get("tokens_per_second", 0.0)
            # æ¥µç«¯ãªå€¤ã‚’é™¤å¤–ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„ä½ã™ãã‚‹å€¤ãªã©ï¼‰
            if duration > 0.01 and duration < 600: total_duration += duration
            if tokens > 0: total_tokens += tokens
            # æ¥µç«¯ãªTPSå€¤ã‚’é™¤å¤–
            if tps > 0.01 and tps < 10000: total_tps += tps; valid_tps_count += 1

        # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ã
        avg_duration = total_duration / total_count if total_count > 0 else 0.0
        avg_tokens = total_tokens / total_count if total_count > 0 else 0.0
        avg_tps = total_tps / valid_tps_count if valid_tps_count > 0 else 0.0

        stats_summary = (
            f"å¹³å‡å¿œç­”æ™‚é–“: **{avg_duration:.2f} ç§’**\n"
            f"å¹³å‡ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: **{avg_tokens:.1f} ãƒˆãƒ¼ã‚¯ãƒ³**\n"
            f"å¹³å‡TPS: **{avg_tps:.2f} tok/s**"
        )
        embed.add_field(name=f"å¿œç­”çµ±è¨ˆ (ç›´è¿‘ {total_count}/{stats_max_len} å›)", value=stats_summary, inline=False)

    embed.set_footer(text=f"å±¥æ­´ä¿æŒæ•°: {HISTORY_LIMIT} | Ollama API: {OLLAMA_API_URL}")
    await interaction.followup.send(embed=embed, ephemeral=True)

# --- BOTèµ·å‹• ---
if __name__ == "__main__":
    if not TOKEN: logger.critical("ç’°å¢ƒå¤‰æ•° 'DISCORD_TOKEN' æœªè¨­å®šã€‚"); sys.exit(1)
    if CHAT_CHANNEL_ID is None: logger.critical("ç’°å¢ƒå¤‰æ•° 'CHAT_CHANNEL_ID' ç„¡åŠ¹ã€‚"); sys.exit(1)
    if aiofiles is None: logger.warning("`aiofiles` æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€‚ä¸€éƒ¨æ©Ÿèƒ½åˆ¶é™ã‚ã‚Šã€‚")

    logger.info("--- Ollama Discord BOT èµ·å‹•ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ ---")
    logger.info(f"ç›£è¦–ãƒãƒ£ãƒ³ãƒãƒ«ID: {CHAT_CHANNEL_ID}")
    logger.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«: {DEFAULT_MODEL or 'æœªè¨­å®š'}")
    logger.info(f"å±¥æ­´ä¿æŒæ•°: {HISTORY_LIMIT}")
    logger.info(f"Ollama API URL: {OLLAMA_API_URL}")
    # System prompt.txt ãƒ‘ã‚¹ã®ãƒ­ã‚°ã‚’å‰Šé™¤
    logger.info(f"ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆDir: {prompts_dir_path}")
    logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ­ãƒ¼ãƒ‰é–“éš”: {PROMPT_RELOAD_INTERVAL_MINUTES} åˆ†")
    logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆæ›´æ–°é–“éš”: {MODEL_UPDATE_INTERVAL_MINUTES} åˆ†")
    logger.info("-------------------------------------------")

    try:
        bot.run(TOKEN, log_handler=None) # æ¨™æº–ã®ãƒ­ã‚®ãƒ³ã‚°ãƒãƒ³ãƒ‰ãƒ©ã‚’ä½¿ã†ã®ã§ None
    except discord.LoginFailure: logger.critical("Discordãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ç¢ºèªè¦ã€‚")
    except discord.PrivilegedIntentsRequired: logger.critical("Message Content Intent ç„¡åŠ¹ã€‚Developer Portalç¢ºèªè¦ã€‚")
    except ImportError as e: logger.critical(f"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: {e}")
    except Exception as e: logger.critical(f"BOTèµ·å‹•ä¸­è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

# --- END OF FILE bot.py ---